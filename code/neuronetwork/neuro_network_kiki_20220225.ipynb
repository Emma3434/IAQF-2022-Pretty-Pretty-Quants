{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import date, timedelta, datetime\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import datetime\n",
    "import backtrader as bt\n",
    "import backtrader.analyzers as btanalyzers\n",
    "\n",
    "from strategy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #1 Load the Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #4 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    train = df.loc[:'2017-12-10',:]\n",
    "    test = df.loc['2017-12-11':, :]\n",
    "    return train, test\n",
    "\n",
    "def check_length(train,test,df):\n",
    "    print('value_counts for training state:\\n',train.state.value_counts())\n",
    "    print('\\n')\n",
    "    print('value_counts for testing state:\\n',test.state.value_counts())\n",
    "    print('\\n')\n",
    "    print('length of train data:',len(train), '\\nlength of test data:',len(test))\n",
    "    print('\\n')\n",
    "    print('proportion of train data:',len(train)/len(df),'\\nproportion of test data:',len(test)/len(df))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #5 Scaling and Transforming the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_transform_data(train, test):\n",
    "    f_columns = train.columns[:-1]\n",
    "    f_transformer = RobustScaler()\n",
    "    f_transformer = f_transformer.fit(train[f_columns].to_numpy())\n",
    "    train.loc[:, f_columns] = f_transformer.transform(train[f_columns].to_numpy())\n",
    "    test.loc[:, f_columns] = f_transformer.transform(test[f_columns].to_numpy())\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #6 Cuting time series into sub sequencies & oneHot encoder  for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape to [#samples, #time_steps, #n_features]\n",
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps),:-1].values \n",
    "        Xs.append(v)        \n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencoder_y(y_train,y_test):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(y_train)\n",
    "    y_train = enc.transform(y_train).toarray()\n",
    "    y_test = enc.transform(y_test).toarray()\n",
    "    return y_train, y_test, enc\n",
    "    # return y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #7 Build LSTM & Bidirectional LSTM Model on Train data in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(train_data):\n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(train_data.iloc[:,-1]),(train_data.iloc[:,-1]))\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bi_LSTM_model(X_train,y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "    keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(units=128,input_shape=[X_train.shape[1], X_train.shape[2]])))\n",
    "    #model.add(keras.layers.Dropout(rate=0.3))\n",
    "    model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(X_train,y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=64,input_shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    #model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model_1(X_train,y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=64,input_shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    #model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bi_LSTM_model_1(X_train,y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "    keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(units=128,input_shape=[X_train.shape[1], X_train.shape[2]])))\n",
    "    #model.add(keras.layers.Dropout(rate=0.3))\n",
    "    model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_LSTM(is_weighted,X_train,y_train,model,weights=None):\n",
    "    if is_weighted:\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_split=0.1,\n",
    "            shuffle=False,\n",
    "            verbose=0,\n",
    "            class_weight=weights)\n",
    "    else:\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_split=0.1,\n",
    "            verbose = 0,\n",
    "            shuffle=False)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #8 Fit Bidirectional LSTM Model on Test data in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model,X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_final_df(enc,y_pred,test):\n",
    "\n",
    "    a = enc.inverse_transform(y_pred)\n",
    "    b = enc.inverse_transform(y_pred).shape[0]\n",
    "    y_pred2 = np.reshape(a, (1, b))[0][-978:]\n",
    "\n",
    "    final_pred_df = test.loc['2018':,:]\n",
    "    final_pred_df = final_pred_df.drop('state', 1)\n",
    "    final_pred_df.insert(loc=test.shape[1]-1,column='state',value=y_pred2) \n",
    "    final_pred_df = final_pred_df.reset_index()\n",
    "    \n",
    "    final_pred_df['state'] = final_pred_df['state'].map({0: -1, 1: 0,2: 1})\n",
    "\n",
    "    test['state'] = test['state'].map({0: -1, 1: 0,2: 1})\n",
    "\n",
    "    final_y_pred = final_pred_df.loc[:,'state']\n",
    "    final_y_test = test.loc['2018':,'state']\n",
    "    \n",
    "    return final_y_test,final_y_pred,final_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_final_df(y_train_noenc,y_test_noenc,y_pred,test):\n",
    "#     enc = onehotencoder_y(y_train_noenc,y_test_noenc)[2]\n",
    "#     a = enc.inverse_transform(y_pred)\n",
    "#     b = enc.inverse_transform(y_pred).shape[0]\n",
    "#     y_pred2 = np.reshape(a, (1, b))[0][-978:]\n",
    "#     final_pred_df = test.loc['2018':,:]\n",
    "#     final_pred_df.insert(loc=test.shape[1],column='State',value=y_pred2)\n",
    "#     final_pred_df = final_pred_df.drop('state', 1)\n",
    "#     final_pred_df['State'] = final_pred_df['State'].map({0: -1, 1: 0,2: 1})\n",
    "#     final_pred_df = final_pred_df.reset_index()\n",
    "#     final_y_pred = final_pred_df.loc[:,'State']\n",
    "    \n",
    "#     test['state'] = test['state'].map({0: -1, 1: 0,2: 1})\n",
    "#     final_y_test = test.loc['2018':,'state']\n",
    "#     return final_y_test,final_y_pred,final_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #9 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(history,X_train, y_train, y_train_noenc,y_test_noenc,X_test,y_test,y_pred,final_y_test,final_y_pred):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='validation')\n",
    "    plt.legend()\n",
    "    print('\\n')\n",
    "    \n",
    "    X_train =X_train[4:]\n",
    "    y_train = y_train[4:]\n",
    "    X_test = X_test[4:]\n",
    "    y_test = y_test[4:]\n",
    "    y_pred = y_pred[4:]\n",
    "    \n",
    "    scores1 = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores1[1], 1 - scores1[1]))   \n",
    "\n",
    "    scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))\n",
    "    print('\\n')\n",
    "    \n",
    "    print('model_evaluate:',model.evaluate(X_test, y_test))\n",
    "    print('\\n')\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(final_y_test, final_y_pred,labels=[-1,0,1])\n",
    "    np.set_printoptions(precision=2)\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Bear', 'Static', 'Bull'],title='Confusion matrix')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #10 Compute CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackTesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operation(dataname,features_list,train_start,strategy,\n",
    "is_weighted = False,is_LSTM=True):\n",
    "    # Read data\n",
    "    df = pd.read_csv(dataname+'.csv', index_col=0)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    # df = df[features_list]\n",
    "    df['state'] = df['state'].map({-1: 0, 0: 1,1: 2})\n",
    "\n",
    "    train = df.loc[train_start:'2017-12-10',:]\n",
    "    test = df.loc['2017-12-11':, :]\n",
    "\n",
    "    train,test = scale_transform_data(train, test)\n",
    "    \n",
    "    time_steps = 3 # Use how many days x to predict next y\n",
    "    X_train, y_train_noenc = create_dataset(train, train.state, time_steps)\n",
    "    X_test, y_test_noenc = create_dataset(test, test.state, time_steps)\n",
    "\n",
    "    y_train,y_test,enc = onehotencoder_y(y_train_noenc,y_test_noenc)\n",
    "\n",
    "    # Get weights\n",
    "    if is_weighted:\n",
    "        weight = weights(train)\n",
    "    else:\n",
    "        weight = None\n",
    "    \n",
    "    if is_LSTM:\n",
    "        model = LSTM_model_1(X_train,y_train)\n",
    "        history = fit_LSTM(is_weighted,X_train,y_train,model,weight)\n",
    "        y_pred = pred(model,X_test)\n",
    "    else:\n",
    "        model = Bi_LSTM_model_1(X_train,y_train)\n",
    "        history = fit_LSTM(is_weighted,X_train,y_train,model,weight)\n",
    "        y_pred = pred(model,X_test)\n",
    "        \n",
    "    \n",
    "    final_y_test, final_y_pred, final_pred_df = compute_final_df(enc,y_pred,test)\n",
    "    \n",
    "    dataf = final_pred_df\n",
    "    dataf['Date']=pd.to_datetime(dataf['Date'])\n",
    "\n",
    "    cerebro = bt.Cerebro()\n",
    "\n",
    "    num = dataf.shape[1]-1\n",
    "    data = PandasData(dataname = dataf,fromdate=datetime.datetime(2018, 1, 2),todate=datetime.datetime(2021, 12, 30),datetime = 0,open = 1,high = 2,low = 3, close = 4,state = num)\n",
    "\n",
    "    # Add data to Cerebro\n",
    "    cerebro.adddata(data)\n",
    "\n",
    "    # Add strategy to Cerebro\n",
    "    cerebro.addstrategy(strategy)\n",
    "\n",
    "    # Default position size\n",
    "    cerebro.addsizer(bt.sizers.SizerFix, stake=1)\n",
    "\n",
    "    # Add analytics to Cerebro\n",
    "    cerebro.addanalyzer(btanalyzers.SharpeRatio, _name='SharpeRatio')\n",
    "    cerebro.addanalyzer(btanalyzers.AnnualReturn, _name='AnnualReturn')\n",
    "    cerebro.addanalyzer(btanalyzers.DrawDown, _name='DrawDown')\n",
    "    # cerebro.addanalyzer(btanalyzers.TimeDrawDown, _name='TimeDrawDown')\n",
    "    cerebro.addanalyzer(btanalyzers.PositionsValue, _name='PositionsValue')\n",
    "    cerebro.addanalyzer(btanalyzers.LogReturnsRolling, _name='LogReturnsRolling')\n",
    "    cerebro.addanalyzer(btanalyzers.PeriodStats, _name='PeriodStats')\n",
    "    cerebro.addanalyzer(btanalyzers.Returns, _name='Returns')\n",
    "    cerebro.addanalyzer(btanalyzers.TradeAnalyzer, _name='TradeAnalyzer')\n",
    "    cerebro.addanalyzer(btanalyzers.Transactions, _name='Transactions')\n",
    "\n",
    "    \n",
    "    # Run Cerebro Engine\n",
    "    start_portfolio_value = cerebro.broker.getvalue()\n",
    "\n",
    "    # cerebro.run()\n",
    "    thestrats = cerebro.run()\n",
    "    thestrat = thestrats[0]\n",
    "\n",
    "    end_portfolio_value = cerebro.broker.getvalue()\n",
    "    pnl = end_portfolio_value - start_portfolio_value\n",
    "    sharpe = thestrat.analyzers.SharpeRatio.get_analysis()['sharperatio']\n",
    "    \n",
    "    #print(f'Starting Portfolio Value: {start_portfolio_value:2f}')\n",
    "    #print(f'Final Portfolio Value: {end_portfolio_value:2f}')\n",
    "    # print('n=',n,'weight=',weight,f'PnL= {pnl:.2f}\\n')\n",
    "    return pnl, sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataname': 'y2_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': -5.437297511816723,\n",
       "  'sharpe': -84.91345266250002},\n",
       " {'dataname': 'y2_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': -7.149506312298399,\n",
       "  'sharpe': -71.11690272672949},\n",
       " {'dataname': 'y2_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': 1.0324471811727562,\n",
       "  'sharpe': -18.37369939298428},\n",
       " {'dataname': 'y2_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': 20.480597100424347,\n",
       "  'sharpe': -7.20750741278443},\n",
       " {'dataname': 'y2_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': 55.68931353087282,\n",
       "  'sharpe': -2.7436712415978772},\n",
       " {'dataname': 'y2_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': 83.79190953961006,\n",
       "  'sharpe': -1.5142058531636218},\n",
       " {'dataname': 'y5_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': 2.384592586358849,\n",
       "  'sharpe': -232.1071362366801},\n",
       " {'dataname': 'y5_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': -2.4807556735850085,\n",
       "  'sharpe': -93.56952159035616},\n",
       " {'dataname': 'y5_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': -3.008136147820551,\n",
       "  'sharpe': -62.798600754824555},\n",
       " {'dataname': 'y5_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': -2.435134742732771,\n",
       "  'sharpe': -75.32930905271706},\n",
       " {'dataname': 'y5_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': 11.20858820238027,\n",
       "  'sharpe': -39.87017970220266},\n",
       " {'dataname': 'y5_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': 5.638740920796408,\n",
       "  'sharpe': -30.97733423239859},\n",
       " {'dataname': 'gmm_1_labeled_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': 37.1118881688235,\n",
       "  'sharpe': -2.764289139804649},\n",
       " {'dataname': 'gmm_1_labeled_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': -2.812577650687672,\n",
       "  'sharpe': -8.906305474373971},\n",
       " {'dataname': 'gmm_1_labeled_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': 310.63406531802866,\n",
       "  'sharpe': -0.3422475889162187},\n",
       " {'dataname': 'gmm_1_labeled_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': 37.605355590563704,\n",
       "  'sharpe': -1.8753601115983916},\n",
       " {'dataname': 'gmm_1_labeled_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': 171.0189539366511,\n",
       "  'sharpe': -0.8276902381244698},\n",
       " {'dataname': 'gmm_1_labeled_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': 171.74971339419062,\n",
       "  'sharpe': -0.7686915211442489},\n",
       " {'dataname': 'hmm_1_labeled_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': 63.64147667516045,\n",
       "  'sharpe': -3.7965937400093774},\n",
       " {'dataname': 'hmm_1_labeled_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': 23.78811171185771,\n",
       "  'sharpe': -13.244414077666494},\n",
       " {'dataname': 'hmm_1_labeled_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': 7.183364978332975,\n",
       "  'sharpe': -9.468531020235714},\n",
       " {'dataname': 'hmm_1_labeled_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': 16.3653445210075,\n",
       "  'sharpe': -6.781265372009411},\n",
       " {'dataname': 'hmm_1_labeled_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'weighted': False,\n",
       "  'LSTM': True,\n",
       "  'pnl': 69.38980754614568,\n",
       "  'sharpe': -0.5570627704443569},\n",
       " {'dataname': 'hmm_1_labeled_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'weighted': False,\n",
       "  'LSTM': False,\n",
       "  'pnl': 144.13615346971892,\n",
       "  'sharpe': -0.8051465753972484}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datanames = ['y1_2003','y2_2003','y3_2003','y4_2003','y5_2003','gmm_1_labeled_2003','hmm_1_labeled_2003']\n",
    "datanames = ['y2_2003','y5_2003','gmm_1_labeled_2003','hmm_1_labeled_2003']\n",
    "features_list = ['Open','High','Low','Close','momentum_rsi', 'volatility_bbp', 'volatility_dcp', 'momentum_ppo', 'momentum_tsi', 'trend_cci', 'momentum_ppo_signal', 'momentum_roc', 'trend_macd', 'trend_macd_signal', 'trend_adx_pos', 'momentum_stoch', 'trend_trix', 'trend_vortex_ind_diff', 'momentum_wr', 'trend_vortex_ind_neg', 'volatility_kcp', 'trend_adx_neg', 'trend_kst_sig', 'momentum_ao', 'volatility_ui', 'trend_kst', 'volatility_dcw', 'volatility_kcw', 'trend_vortex_ind_pos','state']\n",
    "train_start_list = ['2003-01-01','2010-01-04','2015-01-02']\n",
    "is_weighted_list = [False]\n",
    "is_LSTM_list = [True,False]\n",
    "\n",
    "pnl_result = []\n",
    "pnl = 0\n",
    "for dataname in datanames:\n",
    "    for train_start in train_start_list:\n",
    "        for is_weighted in is_weighted_list:\n",
    "            for is_LSTM in is_LSTM_list:\n",
    "                pnl, sharpe = operation(dataname,features_list,train_start,MarketStatus,is_weighted,is_LSTM)\n",
    "                pnl_dic = {'dataname':dataname,\n",
    "                            'train_start':train_start,\n",
    "                            'weighted':is_weighted,\n",
    "                            'LSTM':is_LSTM,\n",
    "                            'pnl':pnl,\n",
    "                            'sharpe':sharpe}\n",
    "                pnl_result.append(pnl_dic)\n",
    "\n",
    "# pnl_result\n",
    "# data_items = pnl_result.items()\n",
    "# data_list = list(data_items)\n",
    "# df_pnl = pd.DataFrame(data_list)\n",
    "# df_pnl.sort_values(by=1,ascending = False)\n",
    "pnl_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_result_df = pd.DataFrame(pnl_result)\n",
    "pnl_result_df.sort_values(by='pnl',ascending=False)\n",
    "pnl_result_df.to_excel('0 nn_result.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataname</th>\n",
       "      <th>train_start</th>\n",
       "      <th>weighted</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>pnl</th>\n",
       "      <th>sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>310.634065</td>\n",
       "      <td>-0.342248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>171.749713</td>\n",
       "      <td>-0.768692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>171.018954</td>\n",
       "      <td>-0.827690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hmm_1_labeled_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>144.136153</td>\n",
       "      <td>-0.805147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y2_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>83.791910</td>\n",
       "      <td>-1.514206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hmm_1_labeled_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>69.389808</td>\n",
       "      <td>-0.557063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hmm_1_labeled_2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>63.641477</td>\n",
       "      <td>-3.796594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y2_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>55.689314</td>\n",
       "      <td>-2.743671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>37.605356</td>\n",
       "      <td>-1.875360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>37.111888</td>\n",
       "      <td>-2.764289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hmm_1_labeled_2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23.788112</td>\n",
       "      <td>-13.244414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y2_2003</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>20.480597</td>\n",
       "      <td>-7.207507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hmm_1_labeled_2003</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16.365345</td>\n",
       "      <td>-6.781265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>y5_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>11.208588</td>\n",
       "      <td>-39.870180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hmm_1_labeled_2003</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7.183365</td>\n",
       "      <td>-9.468531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>y5_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.638741</td>\n",
       "      <td>-30.977334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>y5_2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.384593</td>\n",
       "      <td>-232.107136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y2_2003</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1.032447</td>\n",
       "      <td>-18.373699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>y5_2003</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.435135</td>\n",
       "      <td>-75.329309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>y5_2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.480756</td>\n",
       "      <td>-93.569522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.812578</td>\n",
       "      <td>-8.906305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>y5_2003</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-3.008136</td>\n",
       "      <td>-62.798601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y2_2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>-5.437298</td>\n",
       "      <td>-84.913453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y2_2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-7.149506</td>\n",
       "      <td>-71.116903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataname train_start  weighted   LSTM         pnl      sharpe\n",
       "14  gmm_1_labeled_2003  2010-01-04     False   True  310.634065   -0.342248\n",
       "17  gmm_1_labeled_2003  2015-01-02     False  False  171.749713   -0.768692\n",
       "16  gmm_1_labeled_2003  2015-01-02     False   True  171.018954   -0.827690\n",
       "23  hmm_1_labeled_2003  2015-01-02     False  False  144.136153   -0.805147\n",
       "5              y2_2003  2015-01-02     False  False   83.791910   -1.514206\n",
       "22  hmm_1_labeled_2003  2015-01-02     False   True   69.389808   -0.557063\n",
       "18  hmm_1_labeled_2003  2003-01-01     False   True   63.641477   -3.796594\n",
       "4              y2_2003  2015-01-02     False   True   55.689314   -2.743671\n",
       "15  gmm_1_labeled_2003  2010-01-04     False  False   37.605356   -1.875360\n",
       "12  gmm_1_labeled_2003  2003-01-01     False   True   37.111888   -2.764289\n",
       "19  hmm_1_labeled_2003  2003-01-01     False  False   23.788112  -13.244414\n",
       "3              y2_2003  2010-01-04     False  False   20.480597   -7.207507\n",
       "21  hmm_1_labeled_2003  2010-01-04     False  False   16.365345   -6.781265\n",
       "10             y5_2003  2015-01-02     False   True   11.208588  -39.870180\n",
       "20  hmm_1_labeled_2003  2010-01-04     False   True    7.183365   -9.468531\n",
       "11             y5_2003  2015-01-02     False  False    5.638741  -30.977334\n",
       "6              y5_2003  2003-01-01     False   True    2.384593 -232.107136\n",
       "2              y2_2003  2010-01-04     False   True    1.032447  -18.373699\n",
       "9              y5_2003  2010-01-04     False  False   -2.435135  -75.329309\n",
       "7              y5_2003  2003-01-01     False  False   -2.480756  -93.569522\n",
       "13  gmm_1_labeled_2003  2003-01-01     False  False   -2.812578   -8.906305\n",
       "8              y5_2003  2010-01-04     False   True   -3.008136  -62.798601\n",
       "0              y2_2003  2003-01-01     False   True   -5.437298  -84.913453\n",
       "1              y2_2003  2003-01-01     False  False   -7.149506  -71.116903"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnl_result_df.sort_values(by='pnl',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataname</th>\n",
       "      <th>train_start</th>\n",
       "      <th>weighted</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>pnl</th>\n",
       "      <th>sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>310.634065</td>\n",
       "      <td>-0.342248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>171.749713</td>\n",
       "      <td>-0.768692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>171.018954</td>\n",
       "      <td>-0.827690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hmm_1_labeled_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>144.136153</td>\n",
       "      <td>-0.805147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>y2_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>83.791910</td>\n",
       "      <td>-1.514206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hmm_1_labeled_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>69.389808</td>\n",
       "      <td>-0.557063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hmm_1_labeled_2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>63.641477</td>\n",
       "      <td>-3.796594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y2_2003</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>55.689314</td>\n",
       "      <td>-2.743671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>37.605356</td>\n",
       "      <td>-1.875360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gmm_1_labeled_2003</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>37.111888</td>\n",
       "      <td>-2.764289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataname train_start  weighted   LSTM         pnl    sharpe\n",
       "14  gmm_1_labeled_2003  2010-01-04     False   True  310.634065 -0.342248\n",
       "17  gmm_1_labeled_2003  2015-01-02     False  False  171.749713 -0.768692\n",
       "16  gmm_1_labeled_2003  2015-01-02     False   True  171.018954 -0.827690\n",
       "23  hmm_1_labeled_2003  2015-01-02     False  False  144.136153 -0.805147\n",
       "5              y2_2003  2015-01-02     False  False   83.791910 -1.514206\n",
       "22  hmm_1_labeled_2003  2015-01-02     False   True   69.389808 -0.557063\n",
       "18  hmm_1_labeled_2003  2003-01-01     False   True   63.641477 -3.796594\n",
       "4              y2_2003  2015-01-02     False   True   55.689314 -2.743671\n",
       "15  gmm_1_labeled_2003  2010-01-04     False  False   37.605356 -1.875360\n",
       "12  gmm_1_labeled_2003  2003-01-01     False   True   37.111888 -2.764289"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pnl_result_df.sort_values(by='pnl',ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
