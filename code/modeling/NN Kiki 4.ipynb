{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting backtrader\n",
      "  Downloading backtrader-1.9.76.123-py2.py3-none-any.whl (410 kB)\n",
      "     -------------------------------------- 410.1/410.1 KB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: backtrader\n",
      "Successfully installed backtrader-1.9.76.123\n"
     ]
    }
   ],
   "source": [
    "! pip install backtrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import date, timedelta, datetime\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import datetime\n",
    "import backtrader as bt\n",
    "import backtrader.analyzers as btanalyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #1 Load the Time Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(n):\n",
    "    if n == 1:\n",
    "        df = pd.read_csv(r'E:\\IAQF\\data updated\\d1.csv',index_col = 0)\n",
    "    elif n == 2:\n",
    "        df = pd.read_csv(r'E:\\IAQF\\data updated\\d2.csv',index_col = 0)\n",
    "    elif n == 3:\n",
    "        df = pd.read_csv(r'E:\\IAQF\\data updated\\d3.csv',index_col = 0)\n",
    "    elif n == 4:\n",
    "        df = pd.read_csv(r'E:\\IAQF\\data updated\\d4.csv',index_col = 0)\n",
    "    elif n == 5:\n",
    "        df = pd.read_csv(r'E:\\IAQF\\data updated\\d5.csv',index_col = 0)\n",
    "    elif n == 6:\n",
    "        df = pd.read_csv(r'E:\\IAQF\\data updated\\data_gmm_1_2003.csv',index_col = 0)\n",
    "    elif n == 7:\n",
    "        df = pd.read_csv(r'E:\\IAQF\\data updated\\data_hmm_1_2003.csv',index_col = 0)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.loc[:,['Open', 'High', 'Low', 'Close','momentum_rsi','trend_macd','volatility_dcp','volatility_dcp','momentum_ppo','trend_cci','T10YIE', 'state']]\n",
    "    #df = df.loc[:,[ 'Close','momentum_rsi','trend_macd','volatility_dcp','volatility_dcp','momentum_ppo','trend_cci','T10YIE', 'state']]\n",
    "    #df = df.loc[:,['Open', 'High', 'Low', 'Close','momentum_rsi', 'volatility_bbp', 'volatility_dcp', 'momentum_ppo', 'momentum_tsi', 'trend_cci', 'momentum_ppo_signal', 'momentum_roc', 'trend_macd', 'trend_macd_signal', 'trend_adx_pos', 'momentum_stoch', 'trend_trix', 'trend_vortex_ind_diff', 'momentum_wr', 'trend_vortex_ind_neg', 'volatility_kcp', 'trend_adx_neg', 'trend_kst_sig', 'momentum_ao', 'volatility_ui', 'trend_kst', 'volatility_dcw', 'volatility_kcw', 'trend_vortex_ind_pos','state']]\n",
    "    df['state'] = df['state'].map({-1: 0, 0: 1,1: 2})\n",
    "    #print('value_counts for state:\\n', df.state.value_counts())\n",
    "    #print('\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #4 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df):\n",
    "    train = df.loc[:'2017-12-10',:]\n",
    "    test = df.loc['2017-12-11':, :]\n",
    "    return train, test\n",
    "\n",
    "def check_length(train,test,df):\n",
    "    print('value_counts for training state:\\n',train.state.value_counts())\n",
    "    print('\\n')\n",
    "    print('value_counts for testing state:\\n',test.state.value_counts())\n",
    "    print('\\n')\n",
    "    print('length of train data:',len(train), '\\nlength of test data:',len(test))\n",
    "    print('\\n')\n",
    "    print('proportion of train data:',len(train)/len(df),'\\nproportion of test data:',len(test)/len(df))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #5 Scaling and Transforming the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_transform_data(train, test):\n",
    "    f_columns = df.columns[:-1]\n",
    "    f_transformer = RobustScaler()\n",
    "    f_transformer = f_transformer.fit(train[f_columns].to_numpy())\n",
    "    train.loc[:, f_columns] = f_transformer.transform(train[f_columns].to_numpy())\n",
    "    test.loc[:, f_columns] = f_transformer.transform(test[f_columns].to_numpy())\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #6 Cuting time series into sub sequencies & oneHot encoder  for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape to [#samples, #time_steps, #n_features]\n",
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps),:-1].values \n",
    "        Xs.append(v)        \n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencoder_y(y_train,y_test):\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc.fit(y_train)\n",
    "    y_train = enc.transform(y_train).toarray()\n",
    "    y_test = enc.transform(y_test).toarray()\n",
    "    return y_train, y_test, enc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #7 Build LSTM & Bidirectional LSTM Model on Train data in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights(train_data):\n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(train_data.iloc[:,-1]),(train_data.iloc[:,-1]))\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bi_LSTM_model(X_train,y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "    keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(units=128,input_shape=[X_train.shape[1], X_train.shape[2]])))\n",
    "    #model.add(keras.layers.Dropout(rate=0.3))\n",
    "    model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(X_train,y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=64,input_shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    #model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_LSTM(weight,X_train,y_train,train_data,model):\n",
    "    if weight == 1:\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=15,\n",
    "            batch_size=32,\n",
    "            validation_split=0.1,\n",
    "            shuffle=False,\n",
    "            verbose=0,\n",
    "            class_weight=weights(train_data))\n",
    "    elif weight == 0:\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=15,\n",
    "            batch_size=32,\n",
    "            validation_split=0.1,\n",
    "            verbose = 0,\n",
    "            shuffle=False)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #8 Fit Bidirectional LSTM Model on Test data in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model,X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_final_df(y_train_noenc,y_test_noenc,y_pred,test):\n",
    "    enc = onehotencoder_y(y_train_noenc,y_test_noenc)[2]\n",
    "    a = enc.inverse_transform(y_pred)\n",
    "    b = enc.inverse_transform(y_pred).shape[0]\n",
    "    y_pred2 = np.reshape(a, (1, b))[0][4:]\n",
    "    final_pred_df = test.loc['2018':,:]\n",
    "    final_pred_df.insert(loc=test.shape[1],column='State',value=y_pred2)\n",
    "    final_pred_df = final_pred_df.drop('state', 1)\n",
    "    final_pred_df['State'] = final_pred_df['State'].map({0: -1, 1: 0,2: 1})\n",
    "    final_pred_df = final_pred_df.reset_index()\n",
    "    final_y_pred = final_pred_df.loc[:,'State']\n",
    "    \n",
    "    test['state'] = test['state'].map({0: -1, 1: 0,2: 1})\n",
    "    final_y_test = test.loc['2018':,'state']\n",
    "    return final_y_test,final_y_pred,final_pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #9 Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(history,X_train, y_train, y_train_noenc,y_test_noenc,X_test,y_test,y_pred,final_y_test,final_y_pred):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='validation')\n",
    "    plt.legend();\n",
    "    print('\\n')\n",
    "    \n",
    "    X_train =X_train[4:]\n",
    "    y_train = y_train[4:]\n",
    "    X_test = X_test[4:]\n",
    "    y_test = y_test[4:]\n",
    "    y_pred = y_pred[4:]\n",
    "    \n",
    "    scores1 = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Accuracy on training data: {}% \\n Error on training data: {}'.format(scores1[1], 1 - scores1[1]))   \n",
    "\n",
    "    scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))\n",
    "    print('\\n')\n",
    "    \n",
    "    print('model_evaluate:',model.evaluate(X_test, y_test))\n",
    "    print('\\n')\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(final_y_test, final_y_pred,labels=[-1,0,1])\n",
    "    np.set_printoptions(precision=2)\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['Bear', 'Static', 'Bull'],title='Confusion matrix')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #10 Compute CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(n,weight,final_test):\n",
    "    if n == 1 and weight == 1:\n",
    "        final_test.to_csv('E:/IAQF/result NN/d1_adjust.csv')\n",
    "    elif n == 1 and weight == 0:\n",
    "        final_test.to_csv('E:/IAQF/result NN/d1_without_adjust.csv')\n",
    "    elif n == 2 and weight == 1:\n",
    "        final_test.to_csv('E:/IAQF/result NN/d2_adjust.csv')\n",
    "    elif n == 2 and weight == 0:\n",
    "        final_test.to_csv('E:/IAQF/result NN/d2_without_adjust.csv')\n",
    "    elif n == 3 and weight == 1:\n",
    "        final_test.to_csv('E:/IAQF/result NN/d3_adjust.csv')\n",
    "    elif n == 3 and weight == 0:\n",
    "        final_test.to_csv('E:/IAQF/result NN/d3_without_adjust.csv')\n",
    "    elif n == 4 and weight == 1:\n",
    "        final_test.to_csv('E:/IAQF/result NN/d4_adjust.csv')\n",
    "    elif n == 4 and weight == 0:\n",
    "        final_test.to_csv('E:/IAQF/result NN/d4_without_adjust.csv')\n",
    "    elif n == 5 and weight == 1:\n",
    "        final_test.to_csv('E:/IAQF/result NN/d5_adjust.csv')\n",
    "    elif n == 5 and weight == 0:\n",
    "        final_test.to_csv('E:/IAQF/result NN/d5_without_adjust.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackTesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPositions(bt.Strategy):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def log(self, txt, dt=None):\n",
    "        \"\"\" Logging function fot this strategy\"\"\"\n",
    "        dt = dt or self.data.datetime[0]\n",
    "        if isinstance(dt, float):\n",
    "            dt = bt.num2date(dt)\n",
    "        print(\"%s, %s\" % (dt, txt))\n",
    "\n",
    "    def print_signal(self):\n",
    "        self.log(\n",
    "            f\"o {self.datas[0].open[0]:7.2f} \"\n",
    "            f\"h {self.datas[0].high[0]:7.2f} \"\n",
    "            f\"l {self.datas[0].low[0]:7.2f} \"\n",
    "            f\"c {self.datas[0].close[0]:7.2f} \"\n",
    "            f\"v {self.datas[0].volume[0]:7.0f} \"\n",
    "        )\n",
    "\n",
    "    def next(self):\n",
    "        self.print_signal()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtrader.feeds import PandasData\n",
    "class PandasData(PandasData):\n",
    "    '''\n",
    "    The ``dataname`` parameter inherited from ``feed.DataBase`` is the pandas\n",
    "    DataFrame\n",
    "    '''\n",
    "    lines = ('state',)\n",
    "    params = (\n",
    "        ('datetime', 0),\n",
    "        ('high', 'High'),\n",
    "        ('low', 'Low'),\n",
    "        ('close', 'Close'),\n",
    "        ('volume', None),\n",
    "        ('openinterest', None),\n",
    "        ('state', 5),\n",
    "    )\n",
    "    datafields = PandasData.datafields + (['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketStatus(bt.Strategy): \n",
    "\n",
    "    def log(self, txt, dt=None):\n",
    "        dt = dt or self.datas[0].datetime.date(0)\n",
    "        #print(f'{dt.isoformat()} {txt}') # Comment this line when running optimization\n",
    "\n",
    "    def __init__(self):\n",
    "        self.dataclose = self.datas[0].close\n",
    "\n",
    "        # Order variable will contain ongoing order details/status\n",
    "        self.order = None\n",
    "\n",
    "        # Instantiate market status\n",
    "        self.state = self.datas[0].state\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Submitted, order.Accepted]:\n",
    "            # An active Buy/Sell order has been submitted/accepted - Nothing to do\n",
    "            return\n",
    "\n",
    "        # Check if an order has been completed\n",
    "        # Attention: broker could reject order if not enough cash\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                self.log(f'BUY EXECUTED, {order.executed.price:.2f}')\n",
    "            elif order.issell():\n",
    "                self.log(f'SELL EXECUTED, {order.executed.price:.2f}')\n",
    "            self.bar_executed = len(self)\n",
    "\n",
    "        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n",
    "            self.log('Order Canceled/Margin/Rejected')\n",
    "\n",
    "        # Reset orders\n",
    "        self.order = None\n",
    "\n",
    "    def next(self):\n",
    "\n",
    "        # Check for open orders\n",
    "        if self.order:\n",
    "            return\n",
    "        \n",
    "        if self.state[0] == 1:\n",
    "            if not self.position:\n",
    "                #print('no position',self.state[0], self.position.size)\n",
    "                self.log(f'BUY CREATE {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "                self.order = self.buy()\n",
    "            elif self.position.size < 0: # already have a sell order\n",
    "                #print('sell position',self.state[0], self.position.size)\n",
    "                self.order = self.close()\n",
    "                self.log(f'CLOSE CREATE {self.dataclose[0]:2f}')\n",
    "                self.log(f'BUY CREATE {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "                self.order = self.buy()\n",
    "            elif self.position.size > 0: # already have a buy order\n",
    "                # pass\n",
    "                # self.log(f'BUY CREATE {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "                # self.order = self.buy()\n",
    "\n",
    "                if len(self) == (self.bar_executed + 5):\n",
    "                    #print('buy position, 5 days',self.state[0], self.position.size)\n",
    "                    # self.order = self.close()\n",
    "                    # self.log(f'CLOSE CREATE {self.dataclose[0]:2f}')\n",
    "                    self.log(f'BUY CREATE {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "                    self.order = self.buy()\n",
    "                    self.log('Chase')\n",
    "                elif len(self) >= (self.bar_executed + 15):\n",
    "                    self.order = self.close()\n",
    "                    self.log(f'CLOSE CREATE {self.dataclose[0]:2f}')\n",
    "                else:\n",
    "                    #print('buy position, less than 5 days',self.state[0], self.position.size)\n",
    "                    pass\n",
    "            else:\n",
    "                #print('error',self.state[0], self.position.size)\n",
    "                pass\n",
    "        \n",
    "        elif self.state[0] == -1:\n",
    "            if not self.position:\n",
    "                #print('no position',self.state[0], self.position.size)                \n",
    "                self.log(f'SELL CREATE {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "                self.order = self.sell()\n",
    "            elif self.position.size > 0: # already have a buy order\n",
    "                #print('sell position',self.state[0], self.position.size)                \n",
    "                self.order = self.close()\n",
    "                self.log(f'CLOSE CREATE {self.dataclose[0]:2f}')\n",
    "                self.log(f'SELL CREATE {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "                self.order = self.sell()\n",
    "            elif self.position.size < 0: # already have a sell order\n",
    "                # pass\n",
    "                # Chase every order\n",
    "                # self.log(f'SELL CREATE {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "                # self.order = self.sell()\n",
    "\n",
    "                # Chase 10 \n",
    "                if len(self) == (self.bar_executed + 5):\n",
    "                    #print('buy position, 5 days',self.state[0], self.position.size)\n",
    "                    # self.order = self.close()\n",
    "                    # self.log(f'CLOSE CREATE {self.dataclose[0]:2f}')\n",
    "                    self.log(f'SELL CREATE {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "                    self.order = self.sell()\n",
    "                    # self.log('Chase')\n",
    "                elif len(self) >= (self.bar_executed + 15):\n",
    "                    self.order = self.close()\n",
    "                    self.log(f'CLOSE CREATE {self.dataclose[0]:2f}')\n",
    "                else:\n",
    "                    #print('buy position, less than 5 days',self.state[0], self.position.size)\n",
    "                    pass\n",
    "\n",
    "            else:\n",
    "                #print('error',self.state[0], self.position.size)\n",
    "                pass\n",
    "        \n",
    "        else:\n",
    "            if not self.position:\n",
    "                #print('0, nothing',self.state[0], self.position.size)\n",
    "                pass\n",
    "            else:\n",
    "                self.log(f'Hold {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "            \n",
    "        # elif self.state[0] == -1:\n",
    "        #     if not self.position:\n",
    "        #         pass\n",
    "        #     else:\n",
    "        #         self.order = self.close()\n",
    "        #         self.log(f'CLOSE CREATE {self.dataclose[0]:2f}')\n",
    "        #     self.log(f'SELL CREATE {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "        #     self.order = self.sell()\n",
    "                \n",
    "        # else:\n",
    "        #     if not self.position:\n",
    "        #         pass\n",
    "        #     else:\n",
    "        #         self.log(f'Hold {self.dataclose[0]:2f} {self.state[0]:2f}')\n",
    "        # print(self.position)\n",
    "\n",
    "\n",
    "            # if len(self) >= (self.bar_executed + 5):\n",
    "            #     self.log(f'CLOSE CREATE {self.dataclose[0]:2f}')\n",
    "            #     self.order = self.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>momentum_rsi</th>\n",
       "      <th>trend_macd</th>\n",
       "      <th>volatility_dcp</th>\n",
       "      <th>volatility_dcp</th>\n",
       "      <th>momentum_ppo</th>\n",
       "      <th>trend_cci</th>\n",
       "      <th>T10YIE</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-11</th>\n",
       "      <td>1569.719971</td>\n",
       "      <td>1573.699951</td>\n",
       "      <td>1569.719971</td>\n",
       "      <td>1573.540039</td>\n",
       "      <td>71.355599</td>\n",
       "      <td>11.798182</td>\n",
       "      <td>0.899957</td>\n",
       "      <td>0.899957</td>\n",
       "      <td>0.762609</td>\n",
       "      <td>110.376969</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-12</th>\n",
       "      <td>1573.530029</td>\n",
       "      <td>1578.609985</td>\n",
       "      <td>1573.530029</td>\n",
       "      <td>1574.920044</td>\n",
       "      <td>71.963060</td>\n",
       "      <td>12.203902</td>\n",
       "      <td>0.920171</td>\n",
       "      <td>0.920171</td>\n",
       "      <td>0.787784</td>\n",
       "      <td>113.208722</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-13</th>\n",
       "      <td>1575.449951</td>\n",
       "      <td>1580.430054</td>\n",
       "      <td>1574.819946</td>\n",
       "      <td>1574.819946</td>\n",
       "      <td>71.844047</td>\n",
       "      <td>12.374713</td>\n",
       "      <td>0.917897</td>\n",
       "      <td>0.917897</td>\n",
       "      <td>0.797831</td>\n",
       "      <td>109.348774</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-14</th>\n",
       "      <td>1575.160034</td>\n",
       "      <td>1577.849976</td>\n",
       "      <td>1567.260010</td>\n",
       "      <td>1567.260010</td>\n",
       "      <td>63.325846</td>\n",
       "      <td>11.764445</td>\n",
       "      <td>0.789380</td>\n",
       "      <td>0.789380</td>\n",
       "      <td>0.757898</td>\n",
       "      <td>78.428810</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-15</th>\n",
       "      <td>1568.900024</td>\n",
       "      <td>1584.780029</td>\n",
       "      <td>1568.900024</td>\n",
       "      <td>1582.079956</td>\n",
       "      <td>70.667844</td>\n",
       "      <td>12.334466</td>\n",
       "      <td>0.953075</td>\n",
       "      <td>0.953075</td>\n",
       "      <td>0.793491</td>\n",
       "      <td>111.107341</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-23</th>\n",
       "      <td>2750.840088</td>\n",
       "      <td>2776.620117</td>\n",
       "      <td>2750.840088</td>\n",
       "      <td>2768.360107</td>\n",
       "      <td>55.721697</td>\n",
       "      <td>1.598689</td>\n",
       "      <td>0.941414</td>\n",
       "      <td>0.941414</td>\n",
       "      <td>0.058593</td>\n",
       "      <td>121.819263</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>2769.340088</td>\n",
       "      <td>2803.879883</td>\n",
       "      <td>2769.340088</td>\n",
       "      <td>2803.739990</td>\n",
       "      <td>59.777151</td>\n",
       "      <td>7.358879</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.999169</td>\n",
       "      <td>0.269159</td>\n",
       "      <td>164.907229</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>2803.899902</td>\n",
       "      <td>2813.590088</td>\n",
       "      <td>2795.709961</td>\n",
       "      <td>2798.350098</td>\n",
       "      <td>58.892209</td>\n",
       "      <td>11.358024</td>\n",
       "      <td>0.914363</td>\n",
       "      <td>0.914363</td>\n",
       "      <td>0.414709</td>\n",
       "      <td>163.360053</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>2798.379883</td>\n",
       "      <td>2807.370117</td>\n",
       "      <td>2791.860107</td>\n",
       "      <td>2801.870117</td>\n",
       "      <td>59.315808</td>\n",
       "      <td>14.642621</td>\n",
       "      <td>0.934143</td>\n",
       "      <td>0.934143</td>\n",
       "      <td>0.533728</td>\n",
       "      <td>141.012788</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>2802.909912</td>\n",
       "      <td>2813.250000</td>\n",
       "      <td>2794.189941</td>\n",
       "      <td>2795.909912</td>\n",
       "      <td>58.221808</td>\n",
       "      <td>16.573697</td>\n",
       "      <td>0.900651</td>\n",
       "      <td>0.900651</td>\n",
       "      <td>0.603262</td>\n",
       "      <td>130.797100</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close  momentum_rsi  \\\n",
       "Date                                                                           \n",
       "2017-12-11  1569.719971  1573.699951  1569.719971  1573.540039     71.355599   \n",
       "2017-12-12  1573.530029  1578.609985  1573.530029  1574.920044     71.963060   \n",
       "2017-12-13  1575.449951  1580.430054  1574.819946  1574.819946     71.844047   \n",
       "2017-12-14  1575.160034  1577.849976  1567.260010  1567.260010     63.325846   \n",
       "2017-12-15  1568.900024  1584.780029  1568.900024  1582.079956     70.667844   \n",
       "...                 ...          ...          ...          ...           ...   \n",
       "2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107     55.721697   \n",
       "2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990     59.777151   \n",
       "2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098     58.892209   \n",
       "2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117     59.315808   \n",
       "2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912     58.221808   \n",
       "\n",
       "            trend_macd  volatility_dcp  volatility_dcp  momentum_ppo  \\\n",
       "Date                                                                   \n",
       "2017-12-11   11.798182        0.899957        0.899957      0.762609   \n",
       "2017-12-12   12.203902        0.920171        0.920171      0.787784   \n",
       "2017-12-13   12.374713        0.917897        0.917897      0.797831   \n",
       "2017-12-14   11.764445        0.789380        0.789380      0.757898   \n",
       "2017-12-15   12.334466        0.953075        0.953075      0.793491   \n",
       "...                ...             ...             ...           ...   \n",
       "2021-12-23    1.598689        0.941414        0.941414      0.058593   \n",
       "2021-12-27    7.358879        0.999169        0.999169      0.269159   \n",
       "2021-12-28   11.358024        0.914363        0.914363      0.414709   \n",
       "2021-12-29   14.642621        0.934143        0.934143      0.533728   \n",
       "2021-12-30   16.573697        0.900651        0.900651      0.603262   \n",
       "\n",
       "             trend_cci  T10YIE  state  \n",
       "Date                                   \n",
       "2017-12-11  110.376969    1.88      1  \n",
       "2017-12-12  113.208722    1.89      1  \n",
       "2017-12-13  109.348774    1.88      1  \n",
       "2017-12-14   78.428810    1.87      1  \n",
       "2017-12-15  111.107341    1.88      1  \n",
       "...                ...     ...    ...  \n",
       "2021-12-23  121.819263    2.47      1  \n",
       "2021-12-27  164.907229    2.50      1  \n",
       "2021-12-28  163.360053    2.50      1  \n",
       "2021-12-29  141.012788    2.53      1  \n",
       "2021-12-30  130.797100    2.58      1  \n",
       "\n",
       "[992 rows x 12 columns]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_data(1)\n",
    "train = train_test_split(df)[0]\n",
    "test = train_test_split(df)[1]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operation():\n",
    "    for n in range(1,8):\n",
    "        for weight in range(0,2):\n",
    "            df = read_data(n)\n",
    "\n",
    "            train = train_test_split(df)[0]\n",
    "            test = train_test_split(df)[1]\n",
    "\n",
    "            #check_length(train,test,df)\n",
    "\n",
    "            train = scale_transform_data(train, test)[0]\n",
    "            test = scale_transform_data(train, test)[1]\n",
    "\n",
    "            time_steps = 10 # Use how many days x to predict next y\n",
    "            X_train, y_train_noenc = create_dataset(train, train.state, time_steps)\n",
    "            X_test, y_test_noenc = create_dataset(test, test.state, time_steps)\n",
    "            #print('X_train.shape:',X_train.shape)\n",
    "            #print('X_test.shape:',X_test.shape)\n",
    "\n",
    "            # oneHot Encoder for y\n",
    "            y_train = onehotencoder_y(y_train_noenc,y_test_noenc)[0]\n",
    "            y_test = onehotencoder_y(y_train_noenc,y_test_noenc)[1]\n",
    "            #print('y_train.shape:',y_train.shape, '\\ny_test.shape:',y_test.shape)\n",
    "            \n",
    "            model = LSTM_model(X_train,y_train)\n",
    "            history = fit_LSTM(weight,X_train,y_train,train,model)\n",
    "            y_pred = pred(model,X_test)\n",
    "            \n",
    "            final_y_test = compute_final_df(y_train_noenc,y_test_noenc,y_pred,test)[0]\n",
    "            final_y_pred = compute_final_df(y_train_noenc,y_test_noenc,y_pred,test)[1]\n",
    "            #evaluate(history,X_train, y_train, y_train_noenc,y_test_noenc,X_test,y_test,y_pred,final_y_test,final_y_pred)\n",
    "            \n",
    "            final_pred_df = compute_final_df(y_train_noenc,y_test_noenc,y_pred,test)[2]\n",
    "            #output(n,weight,final_pred_df)\n",
    "            final_pred_df.State.value_counts()\n",
    "            \n",
    "            dataf = final_pred_df\n",
    "            dataf['Date']=pd.to_datetime(dataf['Date'])\n",
    "            \n",
    "            cerebro = bt.Cerebro()\n",
    "\n",
    "            num = dataf.shape[1]-1\n",
    "            data = PandasData(dataname = dataf,fromdate=datetime.datetime(2018, 1, 2),todate=datetime.datetime(2021, 12, 30),datetime = 0,open = 1,high = 2,low = 3, close = 4,state = num)\n",
    "\n",
    "            # Add data to Cerebro\n",
    "            cerebro.adddata(data)\n",
    "\n",
    "            # Add strategy to Cerebro\n",
    "            cerebro.addstrategy(MarketStatus)\n",
    "\n",
    "            # Default position size\n",
    "            cerebro.addsizer(bt.sizers.SizerFix, stake=1)\n",
    "\n",
    "            # Add analytics to Cerebro\n",
    "            cerebro.addanalyzer(btanalyzers.SharpeRatio, _name='SharpeRatio')\n",
    "            cerebro.addanalyzer(btanalyzers.AnnualReturn, _name='AnnualReturn')\n",
    "            cerebro.addanalyzer(btanalyzers.DrawDown, _name='DrawDown')\n",
    "            # cerebro.addanalyzer(btanalyzers.TimeDrawDown, _name='TimeDrawDown')\n",
    "            cerebro.addanalyzer(btanalyzers.PositionsValue, _name='PositionsValue')\n",
    "            cerebro.addanalyzer(btanalyzers.LogReturnsRolling, _name='LogReturnsRolling')\n",
    "            cerebro.addanalyzer(btanalyzers.PeriodStats, _name='PeriodStats')\n",
    "            cerebro.addanalyzer(btanalyzers.Returns, _name='Returns')\n",
    "            cerebro.addanalyzer(btanalyzers.TradeAnalyzer, _name='TradeAnalyzer')\n",
    "            cerebro.addanalyzer(btanalyzers.Transactions, _name='Transactions')\n",
    "\n",
    "            if __name__ == '__main__':\n",
    "                # Run Cerebro Engine\n",
    "                start_portfolio_value = cerebro.broker.getvalue()\n",
    "\n",
    "                # cerebro.run()\n",
    "                thestrats = cerebro.run()\n",
    "                thestrat = thestrats[0]\n",
    "\n",
    "                end_portfolio_value = cerebro.broker.getvalue()\n",
    "                pnl = end_portfolio_value - start_portfolio_value\n",
    "\n",
    "                #print(f'Starting Portfolio Value: {start_portfolio_value:2f}')\n",
    "                #print(f'Final Portfolio Value: {end_portfolio_value:2f}')\n",
    "                print('n=',n,'weight=',weight,f'PnL= {pnl:.2f}\\n')\n",
    "            \n",
    "            #if n == 2 and weight ==1:\n",
    "                #return final_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n= 1 weight= 0 PnL= 0.00\n",
      "\n",
      "n= 1 weight= 1 PnL= 2.04\n",
      "\n",
      "n= 2 weight= 0 PnL= 5.88\n",
      "\n",
      "n= 2 weight= 1 PnL= 6.94\n",
      "\n",
      "n= 3 weight= 0 PnL= 0.00\n",
      "\n",
      "n= 3 weight= 1 PnL= 3.64\n",
      "\n",
      "n= 4 weight= 0 PnL= 0.00\n",
      "\n",
      "n= 4 weight= 1 PnL= 9.74\n",
      "\n",
      "n= 5 weight= 0 PnL= 0.00\n",
      "\n",
      "n= 5 weight= 1 PnL= -1.53\n",
      "\n",
      "n= 6 weight= 0 PnL= 38.93\n",
      "\n",
      "n= 6 weight= 1 PnL= 50.92\n",
      "\n",
      "n= 7 weight= 0 PnL= 61.83\n",
      "\n",
      "n= 7 weight= 1 PnL= 52.65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "operation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackTesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>momentum_rsi</th>\n",
       "      <th>volatility_bbp</th>\n",
       "      <th>volatility_dcp</th>\n",
       "      <th>momentum_ppo</th>\n",
       "      <th>momentum_tsi</th>\n",
       "      <th>trend_cci</th>\n",
       "      <th>momentum_ppo_signal</th>\n",
       "      <th>momentum_roc</th>\n",
       "      <th>trend_macd</th>\n",
       "      <th>...</th>\n",
       "      <th>volatility_kcp</th>\n",
       "      <th>trend_adx_neg</th>\n",
       "      <th>trend_kst_sig</th>\n",
       "      <th>momentum_ao</th>\n",
       "      <th>volatility_ui</th>\n",
       "      <th>trend_kst</th>\n",
       "      <th>volatility_dcw</th>\n",
       "      <th>volatility_kcw</th>\n",
       "      <th>trend_vortex_ind_pos</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>0.763334</td>\n",
       "      <td>0.392436</td>\n",
       "      <td>0.546789</td>\n",
       "      <td>0.331556</td>\n",
       "      <td>0.972254</td>\n",
       "      <td>0.223726</td>\n",
       "      <td>0.416932</td>\n",
       "      <td>0.184818</td>\n",
       "      <td>0.931015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362952</td>\n",
       "      <td>-0.645843</td>\n",
       "      <td>0.413976</td>\n",
       "      <td>0.803042</td>\n",
       "      <td>-0.563848</td>\n",
       "      <td>0.387874</td>\n",
       "      <td>-0.727937</td>\n",
       "      <td>-0.873797</td>\n",
       "      <td>0.171424</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>1.009173</td>\n",
       "      <td>0.619581</td>\n",
       "      <td>0.524230</td>\n",
       "      <td>0.373637</td>\n",
       "      <td>1.020410</td>\n",
       "      <td>0.516070</td>\n",
       "      <td>0.417758</td>\n",
       "      <td>0.499525</td>\n",
       "      <td>1.010364</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015932</td>\n",
       "      <td>-0.780194</td>\n",
       "      <td>0.414248</td>\n",
       "      <td>0.828503</td>\n",
       "      <td>-0.563848</td>\n",
       "      <td>0.382116</td>\n",
       "      <td>-0.554112</td>\n",
       "      <td>-0.875997</td>\n",
       "      <td>0.380330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>1.143704</td>\n",
       "      <td>0.701671</td>\n",
       "      <td>0.459992</td>\n",
       "      <td>0.424942</td>\n",
       "      <td>1.087306</td>\n",
       "      <td>0.723207</td>\n",
       "      <td>0.429618</td>\n",
       "      <td>0.327892</td>\n",
       "      <td>1.107173</td>\n",
       "      <td>...</td>\n",
       "      <td>1.315114</td>\n",
       "      <td>-0.886434</td>\n",
       "      <td>0.414053</td>\n",
       "      <td>0.904297</td>\n",
       "      <td>-0.563850</td>\n",
       "      <td>0.396266</td>\n",
       "      <td>-0.416259</td>\n",
       "      <td>-0.878304</td>\n",
       "      <td>0.618164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>1.351468</td>\n",
       "      <td>0.879943</td>\n",
       "      <td>0.546823</td>\n",
       "      <td>0.503721</td>\n",
       "      <td>1.188843</td>\n",
       "      <td>0.978949</td>\n",
       "      <td>0.456305</td>\n",
       "      <td>0.333169</td>\n",
       "      <td>1.255571</td>\n",
       "      <td>...</td>\n",
       "      <td>1.870013</td>\n",
       "      <td>-1.004179</td>\n",
       "      <td>0.417039</td>\n",
       "      <td>1.011127</td>\n",
       "      <td>-0.579606</td>\n",
       "      <td>0.429284</td>\n",
       "      <td>-0.295415</td>\n",
       "      <td>-0.871259</td>\n",
       "      <td>1.019058</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>1.405640</td>\n",
       "      <td>0.792764</td>\n",
       "      <td>0.536593</td>\n",
       "      <td>0.568733</td>\n",
       "      <td>1.279728</td>\n",
       "      <td>0.985948</td>\n",
       "      <td>0.491847</td>\n",
       "      <td>0.495910</td>\n",
       "      <td>1.379082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.846394</td>\n",
       "      <td>-1.078818</td>\n",
       "      <td>0.424748</td>\n",
       "      <td>1.171421</td>\n",
       "      <td>-0.579606</td>\n",
       "      <td>0.470972</td>\n",
       "      <td>-0.393115</td>\n",
       "      <td>-0.872691</td>\n",
       "      <td>1.310662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  momentum_rsi  volatility_bbp  volatility_dcp  momentum_ppo  \\\n",
       "0 2018-01-02      0.763334        0.392436        0.546789      0.331556   \n",
       "1 2018-01-03      1.009173        0.619581        0.524230      0.373637   \n",
       "2 2018-01-04      1.143704        0.701671        0.459992      0.424942   \n",
       "3 2018-01-05      1.351468        0.879943        0.546823      0.503721   \n",
       "4 2018-01-08      1.405640        0.792764        0.536593      0.568733   \n",
       "\n",
       "   momentum_tsi  trend_cci  momentum_ppo_signal  momentum_roc  trend_macd  \\\n",
       "0      0.972254   0.223726             0.416932      0.184818    0.931015   \n",
       "1      1.020410   0.516070             0.417758      0.499525    1.010364   \n",
       "2      1.087306   0.723207             0.429618      0.327892    1.107173   \n",
       "3      1.188843   0.978949             0.456305      0.333169    1.255571   \n",
       "4      1.279728   0.985948             0.491847      0.495910    1.379082   \n",
       "\n",
       "   ...  volatility_kcp  trend_adx_neg  trend_kst_sig  momentum_ao  \\\n",
       "0  ...        0.362952      -0.645843       0.413976     0.803042   \n",
       "1  ...        1.015932      -0.780194       0.414248     0.828503   \n",
       "2  ...        1.315114      -0.886434       0.414053     0.904297   \n",
       "3  ...        1.870013      -1.004179       0.417039     1.011127   \n",
       "4  ...        1.846394      -1.078818       0.424748     1.171421   \n",
       "\n",
       "   volatility_ui  trend_kst  volatility_dcw  volatility_kcw  \\\n",
       "0      -0.563848   0.387874       -0.727937       -0.873797   \n",
       "1      -0.563848   0.382116       -0.554112       -0.875997   \n",
       "2      -0.563850   0.396266       -0.416259       -0.878304   \n",
       "3      -0.579606   0.429284       -0.295415       -0.871259   \n",
       "4      -0.579606   0.470972       -0.393115       -0.872691   \n",
       "\n",
       "   trend_vortex_ind_pos  State  \n",
       "0              0.171424      1  \n",
       "1              0.380330      1  \n",
       "2              0.618164      1  \n",
       "3              1.019058      1  \n",
       "4              1.310662      1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = final_pred_df\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def Bi_LSTM_model(X_train,y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "    keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(units=128,input_shape=[X_train.shape[1], X_train.shape[2]])))\n",
    "    model.add(keras.layers.Dropout(rate=0.3))\n",
    "    model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[:,['Open', 'High', 'Low', 'Close','momentum_rsi','trend_macd','volatility_dcp','volatility_dcp','momentum_ppo','trend_cci','T10YIE', 'state']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n = 2  weight = 1  PNL = 3.94\n",
    "n = 2  weight = 0  PNL = 13.48\n",
    "n = 5  weight = 1  PNL = -0.06\n",
    "n = 5  weight = 0  PNL = -1.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[:,['Open', 'High', 'Low', 'Close','momentum_rsi','trend_macd','volatility_dcp','volatility_dcp','momentum_ppo','trend_cci','T10YIE', 'state']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def LSTM_model(X_train,y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=64,input_shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    #model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n = 5  weight = 1  PNL =-0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.loc[:,[ 'Close','momentum_rsi','trend_macd','volatility_dcp','volatility_dcp','momentum_ppo','trend_cci','T10YIE', 'state']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def LSTM_model(X_train,y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=64,input_shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    #model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n = 2  weight = 0  PNL = 7.92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 4 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[:,['Open', 'High', 'Low', 'Close','momentum_rsi', 'volatility_bbp', 'volatility_dcp', 'momentum_ppo', 'momentum_tsi', 'trend_cci', 'momentum_ppo_signal', 'momentum_roc', 'trend_macd', 'trend_macd_signal', 'trend_adx_pos', 'momentum_stoch', 'trend_trix', 'trend_vortex_ind_diff', 'momentum_wr', 'trend_vortex_ind_neg', 'volatility_kcp', 'trend_adx_neg', 'trend_kst_sig', 'momentum_ao', 'volatility_ui', 'trend_kst', 'volatility_dcw', 'volatility_kcw', 'trend_vortex_ind_pos','state']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def LSTM_model(X_train,y_train):\n",
    "    model = keras.Sequential()\n",
    "    model.add(LSTM(units=64,input_shape=[X_train.shape[1], X_train.shape[2]]))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    #model.add(keras.layers.Dense(units=64, activation='relu'))\n",
    "    #model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(units=32, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(rate=0.5))\n",
    "    model.add(keras.layers.Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n= 1 weight= 0 PnL= 0.00\n",
    "\n",
    "n= 1 weight= 1 PnL= 1.09\n",
    "\n",
    "n= 2 weight= 0 PnL= -7.75\n",
    "\n",
    "n= 2 weight= 1 PnL= -4.02\n",
    "\n",
    "n= 3 weight= 0 PnL= 0.00\n",
    "\n",
    "n= 3 weight= 1 PnL= 3.32\n",
    "\n",
    "n= 4 weight= 0 PnL= 0.00\n",
    "\n",
    "n= 4 weight= 1 PnL= 5.54\n",
    "\n",
    "n= 5 weight= 0 PnL= 0.00\n",
    "\n",
    "n= 5 weight= 1 PnL= -2.30\n",
    "\n",
    "n= 6 weight= 0 PnL= 315.98\n",
    "\n",
    "n= 6 weight= 1 PnL= -2.05\n",
    "\n",
    "n= 7 weight= 0 PnL= -0.51\n",
    "\n",
    "n= 7 weight= 1 PnL= -8.57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 5 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
