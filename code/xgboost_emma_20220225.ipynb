{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from ta import add_all_ta_features\n",
    "from ta.trend import ema_indicator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import datetime\n",
    "\n",
    "from strategy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "xg_grid = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cerebro(dataname,train_start,random_grid,strategy):\n",
    "    df = pd.read_csv(dataname+'.csv',index_col=0)\n",
    "    \n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    X_train, y_train = df.loc[train_start:'2018-01-01',:].iloc[:,:-2], df.loc[train_start:'2018-01-01']['state']\n",
    "    X_test, y_test = df.loc['2018-01-01':'2022-01-01',:].iloc[:,:-2], df.loc['2018-01-01':'2022-01-01']['state']\n",
    "\n",
    "    xg = XGBClassifier()\n",
    "    xg_random = RandomizedSearchCV(estimator = xg, param_distributions = random_grid, n_iter = 100, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "    xg_random.fit(X_train, y_train)\n",
    "    params = xg_random.best_params_\n",
    "\n",
    "    model = XGBClassifier(**params).fit(X_train, y_train)\n",
    "\n",
    "    # model = XGBClassifier().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    score = model.score(X_test,y_test)\n",
    "    f1 = f1_score(y_pred,y_test,average='weighted')\n",
    "\n",
    "    df.loc['2018-01-01':'2022-01-01',['state']] = y_pred.reshape(-1,1)\n",
    "\n",
    "\n",
    "    # Backtesting\n",
    "    # df['Date']=pd.to_datetime(df.index)\n",
    "    df = df.reset_index()\n",
    "    # state_column = df.shape[1]-1\n",
    "    #     # Instantiate Cerebro engine\n",
    "    # cerebro = bt.Cerebro()\n",
    "\n",
    "    # data = PandasData(\n",
    "    #     dataname = df,\n",
    "    #     fromdate=datetime.datetime(2018, 1, 2),\n",
    "    #     todate=datetime.datetime(2021, 12, 30),\n",
    "    #     datetime = 0,\n",
    "    #     open = 1,\n",
    "    #     high = 2,\n",
    "    #     low = 3,\n",
    "    #     close = 4,\n",
    "    #     state = state_column,\n",
    "    # )\n",
    "\n",
    "    # # Add data to Cerebro\n",
    "    # cerebro.adddata(data)\n",
    "\n",
    "    # # Add strategy to Cerebro\n",
    "    # cerebro.addstrategy(strategy)\n",
    "\n",
    "    # # Default position size\n",
    "    # cerebro.addsizer(bt.sizers.SizerFix, stake=1)\n",
    "\n",
    "    # # Add analytics to Cerebro\n",
    "    # cerebro.addanalyzer(btanalyzers.SharpeRatio, _name='SharpeRatio')\n",
    "    # cerebro.addanalyzer(btanalyzers.AnnualReturn, _name='AnnualReturn')\n",
    "    # cerebro.addanalyzer(btanalyzers.DrawDown, _name='DrawDown')\n",
    "    # cerebro.addanalyzer(btanalyzers.TimeDrawDown, _name='TimeDrawDown')\n",
    "    # cerebro.addanalyzer(btanalyzers.PositionsValue, _name='PositionsValue')\n",
    "    # cerebro.addanalyzer(btanalyzers.LogReturnsRolling, _name='LogReturnsRolling')\n",
    "    # cerebro.addanalyzer(btanalyzers.PeriodStats, _name='PeriodStats')\n",
    "    # cerebro.addanalyzer(btanalyzers.Returns, _name='Returns')\n",
    "    # cerebro.addanalyzer(btanalyzers.TradeAnalyzer, _name='TradeAnalyzer')\n",
    "    # cerebro.addanalyzer(btanalyzers.Transactions, _name='Transactions')\n",
    "\n",
    "    # # Run Cerebro Engine\n",
    "    # start_portfolio_value = cerebro.broker.getvalue()\n",
    "\n",
    "    # # cerebro.run()\n",
    "    # thestrats = cerebro.run()\n",
    "    # thestrat = thestrats[0]\n",
    "\n",
    "    # end_portfolio_value = cerebro.broker.getvalue()\n",
    "    # pnl = end_portfolio_value - start_portfolio_value\n",
    "\n",
    "    # # print(f'Starting Portfolio Value: {start_portfolio_value:2f}')\n",
    "    # # print(f'Final Portfolio Value: {end_portfolio_value:2f}')\n",
    "    # # print(f'PnL: {pnl:.2f}\\n')\n",
    "\n",
    "\n",
    "    # sharpe = thestrat.analyzers.SharpeRatio.get_analysis()['sharperatio']\n",
    "    # # print(thestrat.analyzers.AnnualReturn.get_analysis())\n",
    "    # # print(thestrat.analyzers.DrawDown.get_analysis())\n",
    "    # # # print(thestrat.analyzers.TimeDrawDown.get_analysis())\n",
    "    # # print(thestrat.analyzers.PositionsValue.get_analysis())\n",
    "    # # print(thestrat.analyzers.LogReturnsRolling.get_analysis())\n",
    "    # # print(thestrat.analyzers.PeriodStats.get_analysis())\n",
    "    # # print(thestrat.analyzers.Returns.get_analysis())\n",
    "    # # print(thestrat.analyzers.TradeAnalyzer.get_analysis())\n",
    "    # # print(thestrat.analyzers.Transactions.get_analysis())\n",
    "    return df,score,f1,params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:42:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:42:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:44:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:44:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:44:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:47:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:47:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:48:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:48:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:49:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:49:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:51:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:52:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:53:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:53:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:54:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:54:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:55:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:55:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:55:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:59:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[18:59:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:00:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:00:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 45 is smaller than n_iter=100. Running 45 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lemon\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:01:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:01:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'dataname': 'y1_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      0  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      0  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      0  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      0  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71      0  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      0  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      0  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      0  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      0  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      0  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9877300613496932,\n",
       "  'f1': 0.9938271604938271,\n",
       "  'params': {'min_child_weight': 5, 'max_depth': 3, 'gamma': 5}},\n",
       " {'dataname': 'y1_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      0  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      0  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      0  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      0  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71      0  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      0  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      0  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      0  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      0  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      0  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9877300613496932,\n",
       "  'f1': 0.9938271604938271,\n",
       "  'params': {'min_child_weight': 10, 'max_depth': 3, 'gamma': 1.5}},\n",
       " {'dataname': 'y1_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      0  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      0  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      0  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      0  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71      0  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      0  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      0  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      0  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      0  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      0  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9877300613496932,\n",
       "  'f1': 0.9938271604938271,\n",
       "  'params': {'min_child_weight': 5, 'max_depth': 3, 'gamma': 0.5}},\n",
       " {'dataname': 'y2_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      1  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      1  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      1  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      1  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71      1  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      1  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      1  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      1  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      1  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      1  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9325153374233128,\n",
       "  'f1': 0.934280050334619,\n",
       "  'params': {'min_child_weight': 10, 'max_depth': 5, 'gamma': 0.5}},\n",
       " {'dataname': 'y2_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      1  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      1  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      1  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      1  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71      1  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      1  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      1  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      1  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      1  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      1  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9263803680981595,\n",
       "  'f1': 0.9284945525703405,\n",
       "  'params': {'min_child_weight': 10, 'max_depth': 3, 'gamma': 0.5}},\n",
       " {'dataname': 'y2_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      1  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      1  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      1  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      1  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71      1  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      1  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      1  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      1  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      1  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      1  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9008179959100204,\n",
       "  'f1': 0.9115097468258593,\n",
       "  'params': {'min_child_weight': 5, 'max_depth': 5, 'gamma': 1}},\n",
       " {'dataname': 'y5_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      0  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      0  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      0  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      0  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71      0  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      0  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      0  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      0  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      0  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      0  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9652351738241309,\n",
       "  'f1': 0.9657919810117808,\n",
       "  'params': {'min_child_weight': 1, 'max_depth': 3, 'gamma': 0.5}},\n",
       " {'dataname': 'y5_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      0  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      0  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      0  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      0  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71      0  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      0  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      0  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      0  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      0  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      0  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9662576687116564,\n",
       "  'f1': 0.9667701320602323,\n",
       "  'params': {'min_child_weight': 10, 'max_depth': 4, 'gamma': 1.5}},\n",
       " {'dataname': 'y5_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      0  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      0  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      0  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      0  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71      0  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      0  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      0  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      0  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      0  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      0  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9611451942740287,\n",
       "  'f1': 0.9603883674273574,\n",
       "  'params': {'min_child_weight': 1, 'max_depth': 4, 'gamma': 0.5}},\n",
       " {'dataname': 'gmm_1_labeled_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      0  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      1  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      0  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      1  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71     -1  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      1  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      1  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      1  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      1  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      1  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9683026584867076,\n",
       "  'f1': 0.9661824672249792,\n",
       "  'params': {'min_child_weight': 1, 'max_depth': 3, 'gamma': 0.5}},\n",
       " {'dataname': 'gmm_1_labeled_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      0  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      1  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      0  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      1  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71     -1  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      1  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      1  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      1  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      1  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      1  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9683026584867076,\n",
       "  'f1': 0.9661824672249792,\n",
       "  'params': {'min_child_weight': 1, 'max_depth': 3, 'gamma': 0.5}},\n",
       " {'dataname': 'gmm_1_labeled_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      0  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      1  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63      0  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62      1  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71     -1  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      1  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      1  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      1  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      1  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      1  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9693251533742331,\n",
       "  'f1': 0.9672584194157168,\n",
       "  'params': {'min_child_weight': 1, 'max_depth': 3, 'gamma': 0.5}},\n",
       " {'dataname': 'hmm_1_labeled_2003',\n",
       "  'train_start': '2003-01-01',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      1  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      1  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63     -1  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62     -1  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71     -1  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      1  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      1  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      1  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      1  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      1  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9120654396728016,\n",
       "  'f1': 0.9088681571585328,\n",
       "  'params': {'min_child_weight': 5, 'max_depth': 3, 'gamma': 5}},\n",
       " {'dataname': 'hmm_1_labeled_2003',\n",
       "  'train_start': '2010-01-04',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      1  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      1  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63     -1  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62     -1  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71     -1  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      1  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      1  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      1  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      1  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      1  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9049079754601227,\n",
       "  'f1': 0.9010673058301221,\n",
       "  'params': {'min_child_weight': 10, 'max_depth': 5, 'gamma': 5}},\n",
       " {'dataname': 'hmm_1_labeled_2003',\n",
       "  'train_start': '2015-01-02',\n",
       "  'df':            Date         Open         High          Low        Close  \\\n",
       "  0    2003-01-02   489.489990   505.179993   489.489990   505.179993   \n",
       "  1    2003-01-03   505.179993   506.230011   502.100006   504.769989   \n",
       "  2    2003-01-06   504.769989   517.530029   504.769989   516.039978   \n",
       "  3    2003-01-07   516.039978   516.650024   510.769989   512.450012   \n",
       "  4    2003-01-08   512.450012   512.450012   504.529999   505.309998   \n",
       "  ...         ...          ...          ...          ...          ...   \n",
       "  4749 2021-12-23  2750.840088  2776.620117  2750.840088  2768.360107   \n",
       "  4750 2021-12-27  2769.340088  2803.879883  2769.340088  2803.739990   \n",
       "  4751 2021-12-28  2803.899902  2813.590088  2795.709961  2798.350098   \n",
       "  4752 2021-12-29  2798.379883  2807.370117  2791.860107  2801.870117   \n",
       "  4753 2021-12-30  2802.909912  2813.250000  2794.189941  2795.909912   \n",
       "  \n",
       "          Adj Close  volatility_bbm  volatility_bbh  volatility_bbl  \\\n",
       "  0      505.179993      505.179993      505.179993      505.179993   \n",
       "  1      504.769989      504.974991      505.384995      504.564987   \n",
       "  2      516.039978      508.663320      519.100860      498.225780   \n",
       "  3      512.450012      509.609993      519.225655      499.994331   \n",
       "  4      505.309998      508.749994      518.012949      499.487039   \n",
       "  ...           ...             ...             ...             ...   \n",
       "  4749  2768.360107     2717.716003     2786.561838     2648.870169   \n",
       "  4750  2803.739990     2722.416504     2800.638241     2644.194767   \n",
       "  4751  2798.350098     2725.344507     2810.062637     2640.626377   \n",
       "  4752  2801.870117     2731.161011     2820.021515     2642.300506   \n",
       "  4753  2795.909912     2738.634009     2822.753554     2654.514464   \n",
       "  \n",
       "        volatility_bbw  ...  momentum_pvo_hist  momentum_kama  others_dr  \\\n",
       "  0           0.000000  ...       0.000000e+00     505.179993 -53.720865   \n",
       "  1           0.162386  ...       0.000000e+00     505.010776  -0.081160   \n",
       "  2           4.103909  ...       0.000000e+00     509.360835   2.232698   \n",
       "  3           3.773734  ...       0.000000e+00     510.634148  -0.695676   \n",
       "  4           3.641457  ...       0.000000e+00     508.391744  -1.393309   \n",
       "  ...              ...  ...                ...            ...        ...   \n",
       "  4749        5.066448  ...      -2.230000e-08    2723.913013   0.648974   \n",
       "  4750        5.746493  ...      -2.040000e-08    2725.955470   1.278009   \n",
       "  4751        6.217058  ...      -1.860000e-08    2729.177026  -0.192239   \n",
       "  4752        6.507160  ...      -1.700000e-08    2734.793633   0.125789   \n",
       "  4753        6.143175  ...      -1.560000e-08    2736.827065  -0.212722   \n",
       "  \n",
       "        others_dlr   others_cr        EMA10       EMA100  T10Y3M  T10YIE  state  \n",
       "  0       0.000000    0.000000   495.928213   503.591429    2.85    1.64      1  \n",
       "  1      -0.081193   -0.081160   497.535809   503.614767    2.83    1.62      1  \n",
       "  2       2.208138    2.149726   500.900203   503.860811    2.88    1.63     -1  \n",
       "  3      -0.698107    1.439095   503.000168   504.030894    2.85    1.62     -1  \n",
       "  4      -1.403107    0.025734   503.420137   504.056222    2.81    1.71     -1  \n",
       "  ...          ...         ...          ...          ...     ...     ...    ...  \n",
       "  4749    0.646877  447.994803  2730.984040  2676.300265    1.43    2.47      1  \n",
       "  4750    1.269911  454.998225  2744.212394  2678.823824    1.42    2.50      1  \n",
       "  4751   -0.192424  453.931299  2754.055613  2681.190680    1.43    2.50      1  \n",
       "  4752    0.125710  454.628085  2762.749159  2683.580372    1.50    2.53      1  \n",
       "  4753   -0.212949  453.448266  2768.778387  2685.804720    1.47    2.58      1  \n",
       "  \n",
       "  [4754 rows x 87 columns],\n",
       "  'score': 0.9038854805725971,\n",
       "  'f1': 0.9122448468987148,\n",
       "  'params': {'min_child_weight': 1, 'max_depth': 3, 'gamma': 5}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datanames = ['y1_2003','y2_2003','y3_2003','y4_2003','y5_2003','gmm_1_labeled_2003','hmm_1_labeled_2003']\n",
    "datanames = ['y1_2003','y2_2003','y5_2003','gmm_1_labeled_2003','hmm_1_labeled_2003']\n",
    "train_start_list = ['2003-01-01','2010-01-04','2015-01-02']\n",
    "\n",
    "pnl_result = []\n",
    "pnl = 0\n",
    "df_result = []\n",
    "for dataname in datanames:\n",
    "    for train_start in train_start_list:\n",
    "        df_final,score,f1,params = run_cerebro(dataname,train_start,xg_grid,MarketStatus)\n",
    "        # pnl_dic = {'dataname':dataname,\n",
    "        #             'train_start':train_start,\n",
    "        #             'pnl':pnl,\n",
    "        #             'sharpe':sharpe,\n",
    "        #             'score':score,\n",
    "        #             'f1':f1,\n",
    "        #             'params':params\n",
    "        #             }\n",
    "        df_dic = {'dataname':dataname,\n",
    "                    'train_start':train_start,\n",
    "                    'df':df_final,\n",
    "                    'score':score,\n",
    "                    'f1':f1,\n",
    "                    'params':params\n",
    "        }\n",
    "        df_result.append(df_dic)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'xg_y1_2003',\n",
      "'xg_y1_2010',\n",
      "'xg_y1_2015',\n",
      "'xg_y2_2003',\n",
      "'xg_y2_2010',\n",
      "'xg_y2_2015',\n",
      "'xg_y5_2003',\n",
      "'xg_y5_2010',\n",
      "'xg_y5_2015',\n",
      "'xg_gm_2003',\n",
      "'xg_gm_2010',\n",
      "'xg_gm_2015',\n",
      "'xg_hm_2003',\n",
      "'xg_hm_2010',\n",
      "'xg_hm_2015',\n"
     ]
    }
   ],
   "source": [
    "df_result_list = df_result\n",
    "for result in df_result_list:\n",
    "    name = 'xg_'+result['dataname'][0:2]+'_'+result['train_start'][0:4]+'.csv'\n",
    "    # print(\"'\"+name+\"',\")\n",
    "    result['df'].to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnl_result_df = pd.DataFrame(pnl_result)\n",
    "pnl_result_df.sort_values(by='pnl',ascending=False)\n",
    "pnl_result_df.to_excel('0 xg_result.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b18ecf447b39d25eae6a9ae9d5694327d58d99c869301a8afbbe0bb2ae2074bb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
